{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Data\n",
    "\n",
    "Consider the following questions: \n",
    "- Who is my customer? \n",
    "- Where should I relocate my plant or headquarters, given the skill set I require of workers? \n",
    "- Where would be a good location for a new store, given my knowledge of my customer? \n",
    "\n",
    "**How would you answer these questions?** This lecture illustrate one set of tools to answer these questions: Get detailed demographic information about the people that live in a given area using the US census.\n",
    "\n",
    "What is the [US census](https://en.wikipedia.org/wiki/United_States_Census)? Every 10 years the US government is required to essentially count all people within the United States and in doing so constructs detailed demographic information about the peopel living and working within fine geographic levels. \n",
    "\n",
    "A new innovation that is of interest to us is the [American Community Survey](https://en.wikipedia.org/wiki/American_Community_Survey). This is a Survey (not a census), but it asks the long-form questions whose answers can then be matched up with the 10 year census in a way to provide information at a **yearly** frequency. So you can find out median household income in zip code 90210 for 2015, 2014, etc. actually only going back to 2010 since this is a new development.\n",
    "\n",
    "A second development is that the US census has a well developed API for which we can directly access the data. In the past, this process would look like this: bulk download `.csv` files, pull what you need, store it, etc. Now on the fly you can get what you want directly (and I think the main user of this are commercial vendors, e.g. like you look at Zillow and some characteristics of that zip code are reported, this is a direct feed from the census). \n",
    "\n",
    "**What are we going to do with it?** We will learn how to use the Census API and then use information to ask who voted for Trump or Clinton in the 2016 Presidential election. This is a nice application because, we know election results at very fine levels of geography, but we will never know individual votes. But we can `merge` the election results up with demographic information at those fine geographic locations and be able to make statements like \"areas with a less educated population were more likely to vote for candidate X\" Along the way, we will learn some more stuff:\n",
    "- Census API\n",
    "- More practice `merge`ing\n",
    "\n",
    "Then this will fit with the next lecture on mapping.\n",
    "\n",
    "#### Getting Started\n",
    "\n",
    "So below are the packages that we need. The first two we know. The `Census` package is the new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a53136ea-a4a8-411e-9121-ffd6cf17f713"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from census import Census # This is new...\n",
    "from us import states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of points. \n",
    "\n",
    "First, you may not have the `Census` package or the `states` package. To get these packages, open your terminal or command prompt and type: `conda install -c conda-forge census` and then the same thing for states (just replace `census`). This should do the trick.\n",
    "\n",
    "Now before we can use this, YOU need to get access. It is very easy, just go here:\n",
    "\n",
    "https://api.census.gov/data/key_signup.html\n",
    "\n",
    "And then follow the instructions. This will give you a personalized key that you can use when interfacing with the Census. If you are having trouble, just use my key.\n",
    "\n",
    "One you have a key, you create a session. The syntax looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "63aa45da-9a1f-405f-bc8a-18c1e68c2795"
    }
   },
   "outputs": [],
   "source": [
    "my_api_key = '34e40301bda77077e24c859c6c6c0b721ad73fc7'\n",
    "# This is my api_key\n",
    "\n",
    "c = Census(my_api_key)\n",
    "# This will create an object c which has methods associated with it.\n",
    "# We will see  these below.\n",
    "\n",
    "type(c) \n",
    "# Per the discussion below, try c.tab and see the options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: Here is then in depth [documentation](https://www.census.gov/content/dam/Census/data/developers/api-user-guide/api-guide.pdf). This provides info about what datasets are available, geographies, \n",
    "\n",
    "Now below is the basic syntax. Here are [some examples](https://pypi.python.org/pypi/census). The quick start is you do `c.acs5.get(stuff here)`. \n",
    "\n",
    "- The first bit `acs5` says use the 5 year America Community Survey. There are other options (`acs3` and `acs1` with the key difference being the geographical level possible.) The `acs5` is the slowest dataset to be updated, but it contains the finest geographic level of detail.\n",
    "- The next git `get` says get the data\n",
    "- Then the stuff in the brackets tells it what to grab. There are essentially three elements: the first one `code` tells it the code associated with the data series you want, (if you want multiple series, create a tuple); the second element describes the geography (we will work through several different levels of geography), the third element is the year.\n",
    "\n",
    "Lets do an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cec40cc2-3548-40d7-9789-59ff49e65114"
    }
   },
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B01001_001E\") # This says grab the geographical name, and  B01001_001E \n",
    "                               # is the population. \n",
    "    \n",
    "state_pop_2015 = c.acs5.get(code, {'for': 'state:'+ states.CA.fips}, year=2015)\n",
    "                                  # Then this element says for \n",
    "                                  # Then the next element says, by state, then the specific state\n",
    "                                  # you are looking for. Here is the trick, states are classified by FIPS numbers\n",
    "                                  # So you then use the `state.CA.fips` which generates the correct\n",
    "                                  # FIPS value for California.\n",
    "\n",
    "print(states.CA.fips)\n",
    "                    \n",
    "state_pop_2015 = pd.DataFrame(state_pop_2015)\n",
    "\n",
    "\n",
    "state_pop_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pop_2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do one more example: Here is population and total foreign born population in that state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e5f8b1e5-1521-4a60-bb51-5bc5bea63d41"
    }
   },
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B01001_001E\",\"B05006_001E\") # This says grab the geographical name, and  B01001_001E \n",
    "                               # is the population; B05006_001E is foreign born population (i.e. immigrants)\n",
    "    \n",
    "state_pop_2015 = c.acs5.get(code, {'for': 'state:'+ states.CA.fips }, year=2015)\n",
    "                                  # Then this element says for \n",
    "                                  # Then the next element says, by state, then the specific state\n",
    "                                  # you are looking for. Here is the trick, states are classified by FIPS numbers\n",
    "                                  # So you then use the state.CA.fips which generates the correct\n",
    "                                  # FIPS value for California.\n",
    "\n",
    "state_pop_2015 = pd.DataFrame(state_pop_2015)\n",
    "\n",
    "\n",
    "state_pop_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost a 1/4 of the population in California is foreign born! Is this correct? Quick check and google this and see the answer that you get. \n",
    "\n",
    "**How do I get information for all the states?** The simple answer is to use `*` which is the [wild card character](https://en.wikipedia.org/wiki/Wildcard_character) for their data: So you just do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B01001_001E\",\"B05006_001E\") # This says grab the geographical name, and  B01001_001E \n",
    "                               # is the population; B05006_001E is foreign born population (i.e. immigrants)\n",
    "    \n",
    "state_pop_2015 = c.acs5.get(code, {'for': 'state:* '}, year=2015)\n",
    "                                  # Everythig is the same now... but the * says take all states\n",
    "\n",
    "state_pop_2015 = pd.DataFrame(state_pop_2015)\n",
    "\n",
    "print(state_pop_2015.shape)\n",
    "\n",
    "state_pop_2015.head()\n",
    "\n",
    "#county_2015[code].astype(float).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**:\n",
    "\n",
    "- **What is the population of the United States? How can I check if correct?**\n",
    "\n",
    "- **What is the foreign born population of the United states?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigating the variables. This is still hard, but you have to put in the work to get what you want. So here is an approach: First, this provides that data sets available for general API calls (most of these are not in the census python wrapper). \n",
    "\n",
    "https://api.census.gov/data.html\n",
    "\n",
    "Then find the \"ACS 5-Year Detailed Tables\". From here select on groups. This will take you here:\n",
    "\n",
    "https://api.census.gov/data/2016/acs/acs5/groups.html\n",
    "\n",
    "This then provides broad catagories to select from. Select on your favorite one. For example, lets click on \"PLACE OF BIRTH FOR THE FOREIGN-BORN POPULATION IN THE UNITED STATES\" taking us here:\n",
    "\n",
    "https://api.census.gov/data/2016/acs/acs5/groups/B05006.html\n",
    "\n",
    "Then you will find the individual catagories available for this subject matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B01001_001E\",\"B05006_001E\",\"B05006_002E\") # This says grab the geographical name, and  B01001_001E \n",
    "                               # is the population; B05006_001E is foreign born population (i.e. immigrants)\n",
    "    \n",
    "state_pop_2015 = c.acs5.get(code, {'for': 'state:* '}, year=2015)\n",
    "                                  # Everythig is the same now... but the * says take all states\n",
    "\n",
    "state_pop_2015 = pd.DataFrame(state_pop_2015)\n",
    "\n",
    "print(state_pop_2015.shape)\n",
    "\n",
    "state_pop_2015.head(10)\n",
    "\n",
    "#county_2015[code].astype(float).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**:\n",
    "\n",
    "- **Go back to the group level. Find a catagory you like (do control + F and search). Then find one or two variables you like. Grab them.**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finer Levels of Geography\n",
    "\n",
    "The state stuff is interesting, but what is really cool is that very detailed levels of geography can be found. Two that may be of interest are:\n",
    "- Counties: We should have a sense of what these are. \n",
    "- [Zip Code Tabulation Areas](https://en.wikipedia.org/wiki/ZIP_Code_Tabulation_Area): This is close to a zip code, but not always. \n",
    "\n",
    "Lets check it out...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B01001_001E\",\"B05006_001E\") # Same Codes:\n",
    "\n",
    "county_2015 = pd.DataFrame(c.acs5.get(code, \n",
    "                                         {'for': 'county:*'}, year=2015))\n",
    "                                         # Same deal, but we specify county then the wild card\n",
    "                                         # On the example page, there are ways do do this, only by state\n",
    "county_2015.head()\n",
    "\n",
    "# HEre is another way to look at only one state...\n",
    "        \n",
    "county_2015[county_2015[\"NAME\"].str.contains(\"Alaska\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1f205ed8-248b-4fd0-81e7-d58cc8bde5ae"
    }
   },
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B19013_001E\", \"B01001_001E\") \n",
    "# The new code I added was median houshold income:\n",
    "    \n",
    "zip_2015 = pd.DataFrame(c.acs5.get(code, \n",
    "                                         {'for': 'zip code tabulation area: 90210, 90059'}, year=2015))\n",
    "\n",
    "zip_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting. We all know the zip code 90210, the zip code 90059 is also in the Los Angeles area, it happens to be part of the \"Compton\" neighborhood. Google it if you don't know what that it. Median income in Beverly Hills is about 138 thousand dollars, Compton is about 34 thousand. If you were selling designer handbags, where do you want to locate? If you owned a \"dollar store\" where would be a good location? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Who voted for Trump? For Clinton?\n",
    "\n",
    "The idea here is to `merge` some demographic characteristics with election results. Here is my mapping out of the approach:\n",
    "- Lets look at the election data (determine the appropriate geography for the Census data)\n",
    "- Pull the Census data\n",
    "- `Merge` it\n",
    "- Learn about `pivot` tables to report some simple \"cuts\" of the data \n",
    "- Next lecture: A more formal statistical analysis next lecture.\n",
    "\n",
    "** Election Data** Below is a link to some election data that I pulled last year, very soon after the election. Note that it is a bit old as the aggregate vote counts are off. One thing to do is to update this data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/mwaugh0328/\"\n",
    "url = url + \"Did-China-Cause-Trump/master/us-election-2016-results-by-county.csv\"\n",
    "\n",
    "election_2016 = pd.read_csv(url)\n",
    "\n",
    "election_2016.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to notice is that Alaska is not broken down by county. This was a problem with the dataset, so below we will just drop Alaska when we look at it. \n",
    "\n",
    "Now here we can use the `unique` method on the dataframe to find the unique entries. Thus this can answer a question: Who ran for election?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n 2016 Number of Canidates\", election_2016.Candidate.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Trump, Clinton, and several third party candidates we have a hard time remembering now. Now who won the popular vote?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_vote = election_2016[election_2016.Candidate == \"Trump\"].VoteCount.sum()\n",
    "clinton_vote = election_2016[election_2016.Candidate == \"Clinton\"].VoteCount.sum()\n",
    "\n",
    "print(\"Clinton Vote\", clinton_vote, \"Trump Vote\", trump_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so Clinton won the election???\n",
    "\n",
    "Back to the data. What we **want** to do is to merge this up with the Census at the county level. How do we do this? The key thing to notice about the election data is that there is this thing called the `CountryFips` code. [This is a five digit number that uniquely identifies a county](https://en.wikipedia.org/wiki/FIPS_county_code). The first two numbers are the same for the state. The last three then pin down the county within the state. **Note** in the `head` above, you don't quite see this, since it is not showing the first zero. Example, the Alabama entries are all ``01***`` but it only shows ``1***``\n",
    "\n",
    "Now lets look at the Census data. Side note, since we do not have the ACS for 2016, we will just use the ACS for 2015. This should be ok as my guess is that there is an very high correlation acros years within narrowly defined geographies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = (\"NAME\",\"B01001_001E\",\"B19013_001E\") # Same Codes:\n",
    "\n",
    "county_2015 = pd.DataFrame(c.acs5.get(code, \n",
    "                                         {'for': 'county:*'}, year=2015))\n",
    "                                         # Same deal, but we specify county then the wild card\n",
    "                                         # On the example page, there are ways do do this, only by state\n",
    "        \n",
    "county_2015 = county_2015.rename(columns = {\"B01001_001E\":\"population\", \"B19013_001E\":\"income\"})\n",
    "\n",
    "print(county_2015.head())\n",
    "\n",
    "county_2015.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this does not include the combined FIPS number, but the state and then the county. So we just need to append one to the other to create our own FIPS number. Notice that the county and the state are stored as strings. So the operation to append is simply just to add the strings (look at the head to note that this was NOT numerical addition). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_2015[\"FIPS\"] = county_2015[\"state\"] + county_2015[\"county\"]\n",
    "\n",
    "county_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets merge them....but first, ask yourself the following questions:\n",
    "- What kind of merge is this? One-to-one, many-to-one?\n",
    "-  What should you expect after the merge takes place?\n",
    "Below is our syntax. HEre is a slightly different modification or our earlier examples, here we specify the key on the left and the key on the right (which in this case have slightly different names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cens_election = pd.merge(county_2015, election_2016, left_on = \"FIPS\", right_on = \"CountyFips\", indicator = True)\n",
    "cens_election.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WHY IS THIS NOT WORKING!!!**\n",
    "\n",
    "The datatypes are not the same. In the census data we need to convert the FIPS number to a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_2015[\"FIPS\"] = county_2015[\"FIPS\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cens_election = pd.merge(county_2015, election_2016, how='inner',\n",
    "                         left_on = \"FIPS\", right_on = \"CountyFips\", indicator = True)\n",
    "\n",
    "# Note by taking the inner, there will be some stuff that is going to be droped. \n",
    "# There are no election results for parts of Alaska...\n",
    "\n",
    "cens_election.head(10)\n",
    "\n",
    "#how='outer', cens_election.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then lets look at the stuff that was thrown out?\n",
    "#cens_election[cens_election[\"_merge\"]!= \"both\"].head()\n",
    "\n",
    "cens_election.dtypes\n",
    "\n",
    "cens_election[\"VoteShare\"] = cens_election.VoteCount / cens_election.CountyTotalVote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Simple Data Analysis\n",
    "\n",
    "Generally, a good approach to analyzing data is to (i) first provide some simple \"cuts\" of the data or plots that illustrate the point you are after then (ii) use formal statistical modeling to establish the result. Here is why this is important: If the data does not pass (i) or the \"plot test\" as one of my former colleague called it, then this is suggest that you should view any results from (ii) with skeptisisim (does not mean it may not be true, just that more needs to be established).\n",
    "\n",
    "So I want to explore the role of income and of urban/rural divide. One way to get at this is the following: create bins by income level...like poor, middle, rich, and look at the share of votes going to Trump by each bin. If we see, Trump's vote share declining as income rises, this suggests that income level in a factor in determining who voted for Trump. We can do the same by population (with less populated counties taken to be rural)...\n",
    "\n",
    "So how do we do this, we can use this nice feature of pandas `.qcut` which create quanties by whatever we specify, then we can use `groupby` those quantiles and create the table we want.\n",
    "\n",
    "Awsome plan! Now to execute, we need to convert the data types so they can be numerically evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cens_election[\"population\"] = cens_election[\"population\"].astype(float)\n",
    "\n",
    "cens_election[\"income\"] = cens_election[\"income\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets take only the Trump votes. This is OK, because notice that we have for each trump entry, both the trump vote and the total number of votes within that country, thus we can construct all votes and all votes for Trump. We don't need to carry around all the other stuff if we are interested in Trump or not Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_trump = cens_election[cens_election.Candidate == \"Trump\"].copy()\n",
    "# So look at only trump stuff...\n",
    "\n",
    "only_trump[\"trump_share\"] = only_trump.VoteCount / only_trump.CountyTotalVote\n",
    "\n",
    "only_trump.head()\n",
    "# Look at it again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the basic syntax to cut the data by different quintiles, then aggregate all votes for trump by income quantile divided by total votes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nquantiles = 4 # This is the number of quintiles, it just allows me to change this at will.\n",
    "\n",
    "labels = [\"quantile \" + str(var) for var in range(1,nquantiles + 1)]\n",
    "\n",
    "# Here I'm goint to use list comprehension to create some lables, like quantile 1, etc.\n",
    "\n",
    "inc_q = pd.qcut(only_trump[\"income\"], # this says take quantiles by income\n",
    "                nquantiles,           # The number of quantiels\n",
    "                labels = labels)      # The labels to go withit.\n",
    "\n",
    "grouped = only_trump.groupby(inc_q)   # Then this is the magic, I can group by it...\n",
    "\n",
    "vote_income_quant = 100*(grouped.VoteCount.sum() / grouped.CountyTotalVote.sum())\n",
    "\n",
    "                                       # Then this says, given the group, some over all votes (for trump)\n",
    "                                       # Then divide by all votes, in total, for that group\n",
    "\n",
    "print(vote_income_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what you see is that the Trump share systematically declines as household income rises. Here is another modification on the `qcut` command which is just to do `.cut` and specify how you want to cut by...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"poor\", \"rich\"]\n",
    "\n",
    "rich_poor = pd.cut(only_trump[\"income\"], # this says take quantiles by income\n",
    "                2,           # This does not do by qunitle, but just buts half in one bin, half in another....\n",
    "                labels = labels)      # The labels to go withit.\n",
    "\n",
    "grouped = only_trump.groupby(rich_poor)   # Then this is the magic, I can group by it...\n",
    "\n",
    "vote_rich_poor = grouped.VoteCount.sum() / grouped.CountyTotalVote.sum()\n",
    "\n",
    "                                       # Then this says, given the group, some over all votes (for trump)\n",
    "                                       # Then divide by all votes, in total, for that group\n",
    "\n",
    "print(vote_rich_poor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think this is the best way to illustrate this, but a similar message is emerging. \n",
    "\n",
    "Now, lets do the same thing by population, so here is this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [\"quantile \" + str(var) for var in range(1,nquantiles + 1)]\n",
    "\n",
    "pop_q = pd.qcut(only_trump[\"population\"], nquantiles, labels = labels)\n",
    "\n",
    "grouped = only_trump.groupby(pop_q)\n",
    "\n",
    "pop_income_quant =  100*(grouped.VoteCount.sum() / grouped.CountyTotalVote.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the two (DataFrames) tables to make one nice illustration. Here we use the `.concat` method that is a way to \"smush\" two dateframes together when we know they have the same exact row length and just want to add a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([vote_income_quant,pop_income_quant], axis = 1)\n",
    "           # This is the concat option, axis = 1, says add the column.\n",
    "\n",
    "combo.columns = [\"Vote Share by Income Quantile\", \"Vote Share by Population Quantile\"]\n",
    "# Make some nice lables...\n",
    "\n",
    "combo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Advanced \"Cuts of the Data\" (Pivot Tables)\n",
    "\n",
    "One issue with the cuts of the data above is that we don't really see within a income quantile, how the population share varies or vise versa. This motivates the use of a `pivot` table, which is essentially a `groupby` operation but will achieve our want more quickly. \n",
    "\n",
    "I also want to add one more layer on top of the analysis. The cuts of the data above always used the continuous indicator of the Trump share. Another approach is to create a discrete variable, call it Red if the majority of the county voted for Trump, and Blue otherwise. then in the stats module estimate what is sometimes called a linear probability model.\n",
    "\n",
    "**Creating the Dummy Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this uses the `np.where` command that issues a condition. The red, blue thing is nice, but I want to create a numerical value that takes the value one or zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_trump[\"red_blue\"] = np.where(only_trump[\"trump_share\"] > 0.50, 1.0, 0.0)\n",
    "                         # The first part is the condition,\n",
    "                         # The second part, \"red\" is if the condition is met\n",
    "                         # The third part, \"blue\" is if the condition is not met.\n",
    "only_trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pivot Table** \n",
    "\n",
    "This is basically an `groupby` like operation, but can be done in a multi-dimensional manner. For example, suppose that we want to see **within** a size category, a relationship between income and the propensity to vote for Trump? To answer this question, we want to create a slice within a population quantile and then see the different income quantiles. We could do this using a `groupby` and using a boolean operation for each different quantile. Or we could use a pivot table and do this in one swoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_trump.pivot_table(\"red_blue\", index = pop_q, columns = inc_q)\n",
    "                       # The first element tells us the data we want to use, in this case the 1 or 0 of going for trump\n",
    "                       # The second element is the row dimension we want to work by, in this case population quintile\n",
    "                       # The thrid element is the column dimension to work by...\n",
    "                       #\n",
    "                       # This is a simple example, note like groupby there is some aggregator function, its the mean. \n",
    "                       # You can specify it by using aggfunc = {Dicionrary for each varible the mean.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting... lets think what this says. Within smaller, counties, the propensity to vote for Trump is very high. The relationship with income is not as clear. At the bottom end of the income distribution, the propensity to go with Trump is low, rises, then dips down. Think of this like, within a size quintile, there is an inverted U with income. Then the peak of the inverted U decreases as size rises. \n",
    "\n",
    "The `pivot` table essentially allowed us to quickly see the joint distribution of the effects of voting for Trump by income and population. And it illustrated something that would be hard to see in a figure, some kind of inverted U shape between income and the Trump Vote. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Exercises:**\n",
    "- Use the `pivot` table as above but change it to `VoteCount` and verify it is doing what it should by size.\n",
    "- What about the `trump_share`, try that option. What do you see.\n",
    "- Does it matter that the index was population and the columns was income. If they were reversed, what happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, lets plot the data and do a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(100*only_trump[\"trump_share\"], \n",
    "           np.log(only_trump[\"income\"]), \n",
    "           s= 0.000085*only_trump[\"population\"], \n",
    "           alpha = 0.35)\n",
    "\n",
    "ax.set_title(\"Income and Trump's Share of Vote \\n\")\n",
    "ax.set_ylabel(\"Log Scale: Median Household Income\") \n",
    "ax.set_xlabel(\"Percent of County Population Voting For Trump\")\n",
    "\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "ylist = [float(var)*0.01 for var in range(975,1225,25)]\n",
    "\n",
    "ylabel_list = np.exp(ylist)            # Now creat the list of lables by converting 5,6,etc. to levels\n",
    "                                       # by taking exp.\n",
    "ylabel_list = np.round(ylabel_list,-2) # Then round it so it looks nice.\n",
    "\n",
    "ax.set_yticklabels(ylabel_list) # Then set the xtick labels.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting...it also supports the different cuts of the data that we have seen. So we see how there is a general negative relationship between income and the Trump share (though even in log space this is not clearly monotonic). This is consistent with the results from the `pivot` table.  A second thing that you can observe is that bigger balls (larger counties) typically have lower vote shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "294d7f5b-f290-4fe8-85b7-4fdc1c1e60d5": {
     "id": "294d7f5b-f290-4fe8-85b7-4fdc1c1e60d5",
     "prev": null,
     "regions": {
      "8ceed0e0-c671-4a2c-80dc-4d3bdfbbf92f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a53136ea-a4a8-411e-9121-ffd6cf17f713",
        "part": "whole"
       },
       "id": "8ceed0e0-c671-4a2c-80dc-4d3bdfbbf92f"
      }
     }
    },
    "5c0dd032-519f-4f70-aa0d-ad59173e0137": {
     "id": "5c0dd032-519f-4f70-aa0d-ad59173e0137",
     "prev": "a88227f0-4753-48e1-aa8e-010e968d375c",
     "regions": {
      "20ca40be-aa22-4c9b-8f30-cb224618c434": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1f205ed8-248b-4fd0-81e7-d58cc8bde5ae",
        "part": "whole"
       },
       "id": "20ca40be-aa22-4c9b-8f30-cb224618c434"
      }
     }
    },
    "94513f4e-192d-4caa-8651-23f5fb88ec14": {
     "id": "94513f4e-192d-4caa-8651-23f5fb88ec14",
     "prev": "b8e4c02a-0dbd-43ae-bb3e-5d9f0aba63ad",
     "regions": {
      "e2aefead-ca87-4d92-8171-e740c652e6a5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cec40cc2-3548-40d7-9789-59ff49e65114",
        "part": "whole"
       },
       "id": "e2aefead-ca87-4d92-8171-e740c652e6a5"
      }
     }
    },
    "a88227f0-4753-48e1-aa8e-010e968d375c": {
     "id": "a88227f0-4753-48e1-aa8e-010e968d375c",
     "prev": "94513f4e-192d-4caa-8651-23f5fb88ec14",
     "regions": {
      "ccadab53-2f16-46d2-a1f1-52f18c7bad9a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e5f8b1e5-1521-4a60-bb51-5bc5bea63d41",
        "part": "whole"
       },
       "id": "ccadab53-2f16-46d2-a1f1-52f18c7bad9a"
      }
     }
    },
    "b8e4c02a-0dbd-43ae-bb3e-5d9f0aba63ad": {
     "id": "b8e4c02a-0dbd-43ae-bb3e-5d9f0aba63ad",
     "prev": "294d7f5b-f290-4fe8-85b7-4fdc1c1e60d5",
     "regions": {
      "1433866e-b10a-452b-8aff-26e9cfde1182": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "63aa45da-9a1f-405f-bc8a-18c1e68c2795",
        "part": "whole"
       },
       "id": "1433866e-b10a-452b-8aff-26e9cfde1182"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
